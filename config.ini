world_width             800         # Simulation area width
world_height            600         # Simulation area height

goal_random_seed        1           # Random number seed for goal; -1 for random seed initialized with current time
goal_width              20.0        # Size of the goal
goal_mass               20.0        # Goal mass (for calculating forces)
goal_quadrant           2           # Goal position

agent_random_seed       2           # Random number seed for agents; -1 for random seed initialized with current time
agent_number            40          # Number of agents in the swarm
agent_radius            3.0         # Size of the agent
agent_mass              1.0         # Mass of the agent
deployment_width        100         # Initial deployment area width
deployment_height       100         # Initial deployment area width
deployment_quadrant     6           # Initial deployment area position

obstacle_random_seed    3           # Random number seed for obstacles; -1 for random seed initialized with current time
obstacle_number         90          # Number of obstacles
obstacle_radius         10.0        # Size of the obstacle; 0.0 for random, specify min and max below
obstacle_radius_min     3.0         # Minimum obstacle radius
obstacle_radius_max     9.0         # Maximum obstacle radius
obstacle_mass           1.0         # Obstacle mass (for calculating forces)

enable_agent_goal_f     1           # enable/disable agent-goal interactions, 0 - disable, 1 - enable
enable_agent_obstacle_f 1           # enable/disable agent-obstacle interactions, 0 - disable, 1 - enable
enable_agent_agent_f    1           # enable/disable agent-agent interactions, 0 - disable, 1 - enable

R                       50.0        # Desired distance R
friction_coefficient    0.5         # Friction coefficient (for stabilization)
range_coefficient       1.5         # Agent visual range coefficient
max_V                   1.2         # Maximum agent velocity
force_law               1           # 0 - Newtonian, 1 - Lennard-Jones

G_agent_agent           1200.0      # Newtonian - Gravitational constant of agent-agent interactions
G_agent_obstacle        1200.0      # Newtonian - Gravitational constant of agent-obstacle interactions
G_agent_goal            1200.0      # Newtonian - Gravitational constant of agent-goal interactions

p_agent_agent           2.0         # Newtonian - (distance_between_objects) ^ p of agent-agent interactions
p_agent_obstacle        2.0         # Newtonian - (distance_between_objects) ^ p of agent-obstacle interactions
p_agent_goal            2.0         # Newtonian - (distance_between_objects) ^ p of agent-goal interactions

max_f_agent_agent_n     1.08        # Newtonian - Force cutoff agent-agent 
max_f_agent_obstacle_n  4.32        # Newtonian - Force cutoff agent-obstacle
max_f_agent_goal_n      1.17        # Newtonian - Force cutoff agent-goal

epsilon_agent_agent     6.75        # LJ - Strength of agent-agent interactions (acceptable values 1.0 - 20.0)
epsilon_agent_obstacle  8.99        # LJ - Strength of agent-obstacle interactions (acceptable values 1.0 - 20.0)
epsilon_agent_goal      10.72       # LJ - Strength of agent-goal interactions (acceptable values 1.0 - 20.0)

c_agent_agent           1.43        # LJ - Attractive agent-agent parameter (acceptable values 1.0 - 10.0)
c_agent_obstacle        4.45        # LJ - Attractive agent-obstacle parameter (acceptable values 1.0 - 10.0)
c_agent_goal            5.25        # LJ - Attractive agent-goal parameter (acceptable values 1.0 - 10.0)

d_agent_agent           2.29        # LJ - Repulsive agent-agent parameter (acceptable values 1.0 - 10.0)
d_agent_obstacle        9.38        # LJ - Repulsive agent-obstacle parameter (acceptable values 1.0 - 10.0)
d_agent_goal            5.19        # LJ - Repulsive agent-goal parameter (acceptable values 1.0 - 10.0)

max_f_agent_agent_lj    1.08        # LJ - Force cutoff agent-agent 
max_f_agent_obstacle_lj 4.32        # LJ - Force cutoff agent-obstacle
max_f_agent_goal_lj     1.87        # LJ - Force cutoff agent-goal

default_mutation_rate	1.0			# DAEDALUS - agents default mutation rate in %
panic_mutation_rate		5.0			# DAEDALUS - agents "panic" mutation rate in %
fitness					1000		# DAEDALUS - agents starting fitness

time_limit              1500                                # CLI only - time limit per run
runs_number             10                                # CLI only - number of runs
run_simulation          1                                   # CLI only - run simulator to get probabilities or use random number generator, 0 - RNG, 1 - simulation
env_probability         0.9                                 # CLI only - used when run_simulation = 0

initialize_from_file    0                                   # Initialize all objects state from scenario file, 0 - disable, 1 - enable
scenario_filename       scenario                            # Scenario filename
results_filename        results                             # CLI only - File name for writing results

n_number                3                                   # CLI only - Number of different n values
k_number                4                                   # CLI only - Number of different k values, k = n will be added automatically
a_b_number              7                                   # CLI only - Number of prior distributions (alpha-beta pairs)
n_array                 100,300,500                         # CLI only - Actual n values
k_array                 3,5,10,15                           # CLI only - Actual k values
alpha_array             1.0,2.10,10.9,2.5,14.5,18.9,98.1    # CLI only - Actual alpha values
beta_array              1.0,18.9,98.1,2.5,14.5,2.10,10.9    # CLI only - Actual beta values
